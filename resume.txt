object: ANNDL_Homework1

content:

NAME_1: name team member 1
LAST-NAME_1, last name team member 1
STUDENT-ID_1: student ID teame member 1
NAME_2: name team member 2 (if any)
LAST-NAME_2, last name team member 2 (if any)
STUDENT-ID_2: student ID teame member 2 (if any)
LEADERBOARD NICKNAME: name of the team in the homework leaderboard
attachments: zip file LEADERBOARD_NICKNAME.zip containing:

your jupyter notebook(s), or the python scripts, used for the homework
a dataset_split.json file indicating how do you split the training set


1. We started from the model provided during the lab lectures to understand how the process worked. 
	-To solve the splitting between the validation and training set we used the parameter validation_split=0.8 in the ImageDataGenerator constructor.
	-To adapt the test images to the input size we use the Image.resize method.
2. After our first submission we tried to change a the architecture adding a dropout layer. The new model showed a slow learning rate and no particular improvements. We tried with different rates of dropout and none of it has increased the score.
3. In order to understand how the Early Stopping function worked we modified the patience and the min_delta values. Increasing the patience of the callback showed us that the model stopped learning and the performance didn't increase. 
4. Increased depth in convolutional layer. We tried to add some convolutional layer to the network simply by changing the depth parameter, after some epochs where the network didn't learn we understood the receptive field was to high and the max-pool layers should be reduced. 
	We tried to modify the convolutional block itself by doubling the convolutional layers in each block. No improvements.
	We tried to completely modify the network structure by building "manually" each layer, consisting in 2x2 3x3 conv block. No improvements.
	We tried to modify the classifier by adding two layer resulting in a network 512->256->128. No improvements.
	We tried to modify the classifier by adding two layer resulting in a network 512->512->256. No improvements.
	Considering the little imporvements using this architecture, without even being able to overfit the training dataset, we fought our model was too simple to complete this task. We decided to switch approach and move to Transfer Learning with vgg16 architecture.
5. Transfer Learning vgg16 freeze=18 final val_acc=0.6808 final train_acc=0.9126
	We firstly tried with the code provided during the laboratory session and setting the freeze value to 18 thus training only the last 5 layers plus the classifier itself. This turned out in a huge performance improvement.

Data Augmentation correction: through the development of our project we observed that applying data_augmentation to the validation set could turn out in a pessimistic evaluation of the model performances so we changed the algorithm to perform the validation split. Instead of using the internal function of DataImageGenerator we implemented an algorithm to split the training set into two separate folders and then apply data augmentation only on the training dataset. This resulted in a more accurate validation score with respect to the test performance. Better val_acc -> Better score.
6. Visualizing the model performances on Tensorboard we saw that the epoch used to evaluate the model on the test set had a lower validation accuracy value w.r.t. the previous one. We tried to load the weights of the model from the checkpoint and then predict. This turned in a better score.
7. Considering all the available architectures saw during lectures vgg16 looked too heavy and not so performing Transfer Learning Xception without fine tuning, only classifier trained
8. Transfer Learning Xception with fine tuning: 
	8.1 Trained only classifier
	8.2 Trained last 6 layers of Xception network
9. Transfer Learning Xception with global average pooling